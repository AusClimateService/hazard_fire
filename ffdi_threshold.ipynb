{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c6d6354-c8c7-4802-8015-aa6e2600aa55",
   "metadata": {},
   "source": [
    "# FFDI and Thresholding\n",
    "\n",
    "code is setup to process the intial bias_input_data into FFDI and thresholding.\n",
    "\n",
    "The FFDI code uses the zarr stores of the individual simulations which requires the rechunking\n",
    "\n",
    "Thresholding uses the FFDI files of the individual simulations\n",
    "\n",
    "Setup to provide both average value for a GWL for a given RCM and values for each year of a GWL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eadbe924-351b-4469-8daf-8034a1de18c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T05:26:52.416583Z",
     "iopub.status.busy": "2025-01-24T05:26:52.415548Z",
     "iopub.status.idle": "2025-01-24T05:26:52.430523Z",
     "shell.execute_reply": "2025-01-24T05:26:52.429056Z",
     "shell.execute_reply.started": "2025-01-24T05:26:52.416451Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import intake\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import pathlib\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from xclim.indices import (\n",
    "    keetch_byram_drought_index,\n",
    "    griffiths_drought_factor,\n",
    "    mcarthur_forest_fire_danger_index\n",
    ")\n",
    "from dask.distributed import Client        \n",
    "import dask\n",
    "import warnings\n",
    "\n",
    "# Needed for the GWL code\n",
    "from importlib import reload\n",
    "# adding folder to the system path\n",
    "sys.path.insert(0, '/g/data/xv83/rxm599/acs/gwls')\n",
    "\n",
    "import gwl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35be1768-a6c2-46d2-bd59-1fa1b7c32a8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T05:26:55.233384Z",
     "iopub.status.busy": "2025-01-24T05:26:55.232541Z",
     "iopub.status.idle": "2025-01-24T05:26:55.240929Z",
     "shell.execute_reply": "2025-01-24T05:26:55.239310Z",
     "shell.execute_reply.started": "2025-01-24T05:26:55.233325Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_dask_client():\n",
    "# Set configuration options\n",
    "    dask.config.set({\n",
    "    'distributed.comm.timeouts.connect': '90s',  # Timeout for connecting to a worker\n",
    "    'distributed.comm.timeouts.tcp': '90s',  # Timeout for TCP communications\n",
    "    })\n",
    "    client = Client()\n",
    "    return client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334f9696-5912-4237-bf0e-a6dacaebfffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T04:33:35.941775Z",
     "iopub.status.busy": "2025-01-24T04:33:35.941289Z",
     "iopub.status.idle": "2025-01-24T04:33:41.206090Z",
     "shell.execute_reply": "2025-01-24T04:33:41.205360Z",
     "shell.execute_reply.started": "2025-01-24T04:33:35.941745Z"
    }
   },
   "source": [
    "# Start Cluster \n",
    "import dask\n",
    "# Set configuration options\n",
    "dask.config.set({\n",
    "    'distributed.comm.timeouts.connect': '90s',  # Timeout for connecting to a worker\n",
    "    'distributed.comm.timeouts.tcp': '90s',  # Timeout for TCP communications\n",
    "})\n",
    "\n",
    "client = Client()\n",
    "#client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d0c9a69-df09-4c33-aa22-296c447357ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T05:27:03.994713Z",
     "iopub.status.busy": "2025-01-24T05:27:03.994102Z",
     "iopub.status.idle": "2025-01-24T05:27:04.004987Z",
     "shell.execute_reply": "2025-01-24T05:27:04.003682Z",
     "shell.execute_reply.started": "2025-01-24T05:27:03.994651Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_model_info(filepath):\n",
    "    filename = filepath.split('/')[-1]  # Get the filename from the full path\n",
    "    filename_no_ext = filename.split('.')[0]  # Remove the file extension\n",
    "    parts = filename_no_ext.split('_')  # Split filename by underscores\n",
    "#    print(parts)\n",
    "    RCM=parts[1]\n",
    "    GCM=parts[2]\n",
    "    \n",
    "    # Extract model name\n",
    "    model_name = filename_no_ext\n",
    "    extension = filename.split('.')[-1]  # Get the extension\n",
    "    \n",
    "    match = '_'.join(parts[1:3])  # Extract match (e.g., EC-Earth3_ssp370_r1i1p1f1)\n",
    "    pathway = parts[3]  # Extract model (e.g., ssp370)\n",
    "    ensemble = parts[4]  # Extract ensemble (e.g., r1i1p1f1)\n",
    "    \n",
    "    return [model_name, extension], RCM, GCM, ensemble, pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a56bdae6-2723-419a-8f41-c4b8ffc9a658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T05:27:05.087834Z",
     "iopub.status.busy": "2025-01-24T05:27:05.087272Z",
     "iopub.status.idle": "2025-01-24T05:27:05.095725Z",
     "shell.execute_reply": "2025-01-24T05:27:05.094078Z",
     "shell.execute_reply.started": "2025-01-24T05:27:05.087777Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_ffdi(pra, tasmaxa, pr_annual, hursmina, sfcWindmaxa):\n",
    "    KBDI = keetch_byram_drought_index(pra, tasmaxa, pr_annual)\n",
    "    DF = griffiths_drought_factor(pra, KBDI)\n",
    "    FFDI = mcarthur_forest_fire_danger_index(DF, tasmaxa, hursmina, sfcWindmaxa)\n",
    "    return FFDI.to_dataset(name='FFDI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80359f48-6b07-457a-b905-43e53fbcf567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T05:27:06.420548Z",
     "iopub.status.busy": "2025-01-24T05:27:06.420008Z",
     "iopub.status.idle": "2025-01-24T05:27:06.432833Z",
     "shell.execute_reply": "2025-01-24T05:27:06.431376Z",
     "shell.execute_reply.started": "2025-01-24T05:27:06.420492Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_threshold(data, time_dim, syear, eyear, var, period):\n",
    "# first set time slice\n",
    "    start=str(syear)+'-01-01'\n",
    "    end=str(eyear)+'-12-31'\n",
    "    nyear=eyear-syear+1; inyear=1./nyear\n",
    "    data = data.sel(**{time_dim: slice(start, end)}).persist() # use file chunking .persist()\n",
    "    print(f\"Processing period {period}\")\n",
    "# days over key thresholds (days/yr)\n",
    "    d3 = (data > 100).sum('time').to_dataset(name='days100') *inyear\n",
    "    d2 = (data > 75).sum('time').to_dataset(name='days75') *inyear\n",
    "    d1 = (data > 50).sum('time').to_dataset(name='days50') *inyear\n",
    "    dss=xr.merge([d1,d2,d3]) \n",
    "    return dss,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c993183b-802a-49cd-a24b-54aac36bc0df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T05:27:08.642505Z",
     "iopub.status.busy": "2025-01-24T05:27:08.641967Z",
     "iopub.status.idle": "2025-01-24T05:27:08.655393Z",
     "shell.execute_reply": "2025-01-24T05:27:08.654097Z",
     "shell.execute_reply.started": "2025-01-24T05:27:08.642449Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_thresholda(data, time_dim, syear, eyear, var, period):\n",
    "# first set time slice\n",
    "    start=str(syear)+'-01-01'\n",
    "    end=str(eyear)+'-12-31'\n",
    "    nyear=eyear-syear+1; inyear=1./nyear\n",
    "    data = data.sel(**{time_dim: slice(start, end)}).persist() # use file chunking .persist()\n",
    "    print(f\"Processing period {period}\")\n",
    "# days over key thresholds (days/yr)\n",
    "#    d100 = data > 100 ; d100.groupby(time_dim.year).mean\n",
    "    d3a=(data > 100 ).groupby('time.year').sum('time').to_dataset(name='days100')\n",
    "    d2a=(data > 75 ).groupby('time.year').sum('time').to_dataset(name='days75')\n",
    "    d1a=(data > 50 ).groupby('time.year').sum('time').to_dataset(name='days50')\n",
    "    d3 = (data > 100).sum('time').to_dataset(name='days100') *inyear\n",
    "    d2 = (data > 75).sum('time').to_dataset(name='days75') *inyear\n",
    "    d1 = (data > 50).sum('time').to_dataset(name='days50') *inyear\n",
    "    dss=xr.merge([d1,d2,d3]) \n",
    "    dsa=xr.merge([d1a,d2a,d3a]) \n",
    "    return dss,data,dsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dfb8655-cf77-42ce-93b8-d13e593d26a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T05:27:27.887194Z",
     "iopub.status.busy": "2025-01-24T05:27:27.886420Z",
     "iopub.status.idle": "2025-01-24T05:27:27.900580Z",
     "shell.execute_reply": "2025-01-24T05:27:27.899128Z",
     "shell.execute_reply.started": "2025-01-24T05:27:27.887131Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_GWL_levels(model_name, GCM, ensemble, pathway, ffdi_data):\n",
    "    CMIP='CMIP6'\n",
    "    GWL_levels = ['1.2', '1.5', '2.0', '3.0']\n",
    "#    GWL_levels = ['1.2']\n",
    "    for GWL in GWL_levels:\n",
    "        print(f\"Processing GWL {GWL} for model: {GCM}, ensemble: {ensemble}, pathway: {pathway}\")\n",
    "        try:\n",
    "            start, end = gwl.get_GWL_syear_eyear(CMIP, GCM, ensemble, pathway,GWL= GWL)\n",
    "        except:\n",
    "            print(f\"No GWL data found for {GWL}\")\n",
    "            d4=0\n",
    "            continue\n",
    "#        ffdi_data=xr.open_zarr('/g/data/ia39/ncra/fire/'+model_name+'_FFDI.zarr')\n",
    "#        ffdi_data=xr.open_zarr('/scratch/xv83/rxm599/biascor/'+model_name+'_FFDI.zarr')\n",
    "        ffdi_data=xr.open_zarr('/scratch/xv83/rxm599/ffdi/'+model_name+'_FFDI.zarr')\n",
    "        d4, ddata, d4a = process_thresholda(ffdi_data.FFDI, 'time', start, end, 'FFDI', GWL)\n",
    "#        d4, ddata = process_threshold(ffdi_data.FFDI, 'time', start, end, 'FFDI', GWL)\n",
    "        output_path = f'/scratch/xv83/rxm599/tmp/{model_name}_GWL{GWL}_ffdi_threshold.nc'\n",
    "        output_path2= f'/scratch/xv83/rxm599/tmp/{model_name}_GWL{GWL}_ffdi_thresholda.nc'\n",
    "        output_path1 = f'/scratch/xv83/rxm599/tmp/{model_name}_GWL{GWL}_ffdi.zarr'\n",
    "        print(f\"Saved  to {output_path}\")\n",
    "        d4.to_netcdf(output_path)\n",
    "        d4a.to_netcdf(output_path2)\n",
    "#        ddata.to_zarr(output_path1)\n",
    "    return d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af03fa4f-001d-49d4-ac8c-5887c0ee59fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T05:27:29.062221Z",
     "iopub.status.busy": "2025-01-24T05:27:29.061671Z",
     "iopub.status.idle": "2025-01-24T05:27:29.068770Z",
     "shell.execute_reply": "2025-01-24T05:27:29.067292Z",
     "shell.execute_reply.started": "2025-01-24T05:27:29.062164Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example code to read from command line if not interactive (just make the cell code)\n",
    "def is_interactive():\n",
    "    import __main__ as main\n",
    "    return not hasattr(main, '__file__')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f116f-8fb0-4c77-bc30-0ab848710367",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def main():\n",
    "    warnings.filterwarnings('ignore')\n",
    "# get RCMs to processes\n",
    "    catalogue_path = '/g/data/ia39/catalogues/bias-output'\n",
    "    mRuns = sorted(glob.glob(catalogue_path + '/*ssp126*.json'))\n",
    "    #mRuns = sorted(glob.glob(catalogue_path + '/*his*.json'))\n",
    "    print(len(mRuns))\n",
    "# start dask client\n",
    "    client = setup_dask_client()\n",
    "# iterate through all modesl\n",
    "    if is_interactive():\n",
    "        print(f\"Dashboard available at: {client.dashboard_link}\")\n",
    "    else:\n",
    "        print(f\"batch:  {client.dashboard_link}\")\n",
    "        \n",
    "    print(mRuns)\n",
    "    for mindex, file in enumerate(mRuns):\n",
    "        print(file)\n",
    "        model_name, RCM, GCM, ensemble, pathway = extract_model_info(file)\n",
    "        var='FFDI'  # not used\n",
    "        if mindex != 91:         #this model failed to convert\n",
    "            print (mindex)\n",
    "            d4=process_GWL_levels(model_name[0],GCM,ensemble,pathway,var)\n",
    "    \n",
    "    print(\"Processing of all catalogues is complete.\")\n",
    "\n",
    "    print(f\"close client {client}\")\n",
    "    client.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b28a70-1e8a-4bd9-8138-ed2ea2507316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaae4b8-f78d-404a-b899-ba4acc5f9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef561196-4c83-452a-b6a2-03bf7a84e866",
   "metadata": {},
   "source": [
    "#dd=xr.open_zarr('/scratch/xv83/rxm599/nobiascor/AGCD-05i_BOM_EC-Earth3_ssp370_r1i1p1f1_BARPA-R_v1-r1_day.zarr')\n",
    "dd1=xr.open_zarr('/scratch/xv83/rxm599/biascor/AGCD-05i_CSIRO_EC-Earth3_ssp370_r1i1p1f1_CCAM-v2203-SN_v1-r1-ACS-QME-BARRA-R2-1980-2022_day.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c3751-9009-40f9-a6a5-a2d6b44b2058",
   "metadata": {},
   "source": [
    "start1='2015'+'-01-01'\n",
    "end1='2035'+'-12-31'\n",
    "start2='2055'+'-01-01'\n",
    "end2='2075'+'-12-31'\n",
    "time_dim='time'\n",
    "rhm=(dd1.hursmaxAdjust + dd1.hursminAdjust)*.5 \n",
    "data1 = rhm.sel(**{time_dim: slice(start1, end1)}).persist() \n",
    "data2 = rhm.sel(**{time_dim: slice(start2, end2)}).persist() \n",
    "data=data2-data1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceaf6f6-867b-424a-b190-1b481c7797bd",
   "metadata": {},
   "source": [
    "(data2.mean('time')- data1.mean('time')).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d783d19-e5fe-4df9-9a44-4d12ffcaa901",
   "metadata": {},
   "source": [
    "plt.subplot(2,1,1); data2.mean('time').plot()\n",
    "plt.subplot(2,1,2); data1.mean('time').plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf90ffe-df96-4a17-83e8-5024d8a6ab50",
   "metadata": {},
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eacb522-ae06-40a6-8815-7f60b265e4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3]",
   "language": "python",
   "name": "conda-env-analysis3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
